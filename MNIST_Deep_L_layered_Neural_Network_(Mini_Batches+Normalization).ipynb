{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "MNIST_Deep_L_layered_Neural_Network_(Mini_Batches+Normalization).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh6zVssXKo14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw3QUyOnmqF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mnist_nn_utils import load_train_test_dataset, softmax, relu, relu_backward, softmax_backward\n",
        "from optimization_algos import random_mini_batches\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gacmCcPXmqGJ",
        "colab_type": "code",
        "outputId": "f9b4284e-8f8d-4927-b017-91609265138d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "X_train, Y_train, X_test, Y_test= load_train_test_dataset(\"Colab\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of the Y_train list:  60000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Length of the Y_test list:  10000\n",
            "\n",
            "Numpy array X_train shape:  (784, 60000)\n",
            "\n",
            "NUmpy array Y_train shape:  (1, 60000)\n",
            "\n",
            "Numpy array X_test shape:  (784, 10000)\n",
            "\n",
            "Numpy array Y_test shape:  (1, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmJST9NFmqGQ",
        "colab_type": "code",
        "outputId": "3cd4fa03-01d0-44c7-ff8d-5380b3ed6efd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''########### ONE HOT ENCODING OF Y_TRAIN #################\n",
        "\n",
        "https://kite.com/python/answers/how-to-do-one-hot-encoding-with-numpy-in-python\n",
        "'''\n",
        "shape=(10,Y_train.size)\n",
        "\n",
        "one_hot=np.zeros(shape)\n",
        "\n",
        "rows=np.arange(Y_train.size)\n",
        "\n",
        "'''\n",
        "Now the one_hot is a matrix with rows equal to Y_train and the number of columns is same as number of classes.\n",
        "one_hot[rows,Y_train]=1 ---- puts the value 1 at (row_number=rows,column_number=Y_train_value)\n",
        "'''\n",
        "one_hot[Y_train,rows]=1\n",
        "\n",
        "print(\"Shape of One Hot encoding\",one_hot.shape)\n",
        "\n",
        "Y_train=one_hot  #Set Y_train to the encoded variable"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of One Hot encoding (10, 60000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FxEPSWpUj6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''############### NORMALIZING THE INPUTS OF TRAIN AND TEST SET #################'''\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uojWl41KN6aL",
        "colab_type": "text"
      },
      "source": [
        "**THE INITIALIZATION THAT WE PERFFORM HERE IS A SOLUTION TO THE VANISHING GRADIENTS PROBLEM**\n",
        "\n",
        "> In our earlier Model we saw that there was a problem with Cost Function decreasing very slowly. The reason for such a problem can be the ReLU function that makes most of the terms zero and hence creating a Vanishing gradient problem. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGx0y0RRmqGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' ########### INITIALIZATION OF L LAYERS IN DEEP NN(INITIALIZING FOR REDUCING VANISHING GRADIENT PROBLEM) ##############'''\n",
        "def initialize_parameters_deep(layer_dims):\n",
        "    \n",
        "    '''Here layer_dims is a python list conataining the dimensions of all the layers'''\n",
        "    np.random.seed(9)\n",
        "    parameters = {}\n",
        "    L = len(layer_dims)\n",
        "    \n",
        "    for l in range(1, L):\n",
        "        \n",
        "        parameters[\"W\"+str(l)]= np.random.randn(layer_dims[l], layer_dims[l-1])*np.sqrt(2/layer_dims[l-1])\n",
        "        parameters[\"b\"+str(l)]= np.zeros((layer_dims[l],1))\n",
        "        \n",
        "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
        "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
        "        \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgf3lDSMmqGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''############### FORWARD PROPAGATION MODULE for L Layers in \"DEEP NN\" ##################'''\n",
        "\n",
        "def linear_forward(A, W, b):\n",
        "    '''We build the LINEAR PART of the Forward Propagation'''\n",
        "    Z= np.dot(W,A)+b\n",
        "    \n",
        "    cache = (A, W, b)\n",
        "    \n",
        "    return Z, cache\n",
        "\n",
        "def linear_activation_forward(A_prev, W, b, activation):\n",
        "    '''This function implements the ACTIVATION PART of the Forward Propagation'''\n",
        "    \n",
        "    if activation ==\"softmax\":\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = softmax(Z)\n",
        "        \n",
        "    elif activation ==\"relu\":\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = relu(Z)\n",
        "        \n",
        "    cache = (linear_cache, activation_cache)\n",
        "    return A, cache\n",
        "\n",
        "def L_model_forward(X, parameters,print_AL=False):\n",
        "    '''\n",
        "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
        "    We use the above two functions in this function\n",
        "    '''\n",
        "    caches=[]\n",
        "    A = X\n",
        "    L = len(parameters)//2    ##number of layers in the neural net\n",
        "    \n",
        "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
        "    for l in range(1, L):\n",
        "        A_prev = A\n",
        "        A, cache = linear_activation_forward(A_prev, parameters[\"W\"+str(l)], parameters[\"b\"+str(l)], \"relu\")\n",
        "        caches.append(cache)\n",
        "        \n",
        "    AL, cache = linear_activation_forward(A, parameters[\"W\"+str(L)], parameters[\"b\"+str(L)], \"softmax\")\n",
        "    caches.append(cache)\n",
        "    \n",
        "    if print_AL==True:\n",
        "      print(AL)\n",
        "    return AL, caches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4zWjIUBmqGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''############### COMPUTE COST ###############'''\n",
        "def compute_cost(AL, Y):\n",
        "    \n",
        "    m = Y.shape[1]\n",
        "    max_val = np.max(AL, axis =0)\n",
        "    exp_val = np.sum(np.exp(AL - max_val), axis =0)\n",
        "    logsoftmax = (AL - max_val) - np.log(exp_val)\n",
        "    cost = -(np.sum(np.multiply(Y,logsoftmax)))/m\n",
        "    \n",
        "    cost = np.squeeze(cost)\n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKKW95pomqGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''################ BACKWARD PROPAGATION MODULE #############'''\n",
        "def linear_backward(dZ, cache):\n",
        "    '''Implement the linear portion of the Backward Propagation'''\n",
        "    A_prev, W, b = cache\n",
        "    m = A_prev.shape[1]\n",
        "    \n",
        "    dW = np.dot(dZ, A_prev.T)/m\n",
        "    db = np.sum(dZ, axis =1, keepdims= True)/m\n",
        "    dA_prev = np.dot(W.T, dZ)\n",
        "    \n",
        "    return dA_prev, dW, db\n",
        "\n",
        "def linear_activation_backward(dA, cache, activation):\n",
        "    \n",
        "    linear_cache, activation_cache = cache\n",
        "    \n",
        "    if activation == \"relu\":\n",
        "        dZ = relu_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "        \n",
        "    elif activation == \"softmax\":\n",
        "        dZ = softmax_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "        \n",
        "    return dA_prev, dW, db\n",
        "\n",
        "def L_model_backward(AL, Y, caches):\n",
        "    \n",
        "    grads={}\n",
        "    m = AL.shape[1]\n",
        "    \n",
        "    Y = Y.reshape(AL.shape)\n",
        "    \n",
        "    L = len(caches)    ##number of layers in the neural net\n",
        "    #print(\"L: \",L)\n",
        "    out = np.zeros((10, m))\n",
        "    dAL = -np.divide(Y,np.maximum(AL,1e-12), out=out, where=Y!=0)\n",
        "    \n",
        "    current_cache = caches[L-1]\n",
        "    \n",
        "    grads[\"dA\"+str(L-1)], grads[\"dW\"+str(L)], grads[\"db\"+str(L)] = linear_activation_backward(dAL, current_cache, activation=\"softmax\")\n",
        "    \n",
        "    #Loop from L-2 to 0\n",
        "    for l in reversed(range(L-1)):\n",
        "        current_cache = caches[l]\n",
        "        #print(\"Value of l:\",l)\n",
        "        dA_prev_temp,dW_temp, db_temp = linear_activation_backward(grads[\"dA\"+str(l+1)], current_cache, activation=\"relu\")\n",
        "        grads[\"dA\"+str(l)] = dA_prev_temp\n",
        "        grads[\"dW\"+str(l+1)] = (dW_temp)/m\n",
        "        grads[\"db\"+str(l+1)] = (db_temp)/m\n",
        "\n",
        "        #print(\"dA\"+str(l)+\":\"+grads[\"dA\"+str(l)],\"\\ndW\"+str(l+1)+\":\"+grads[\"W\"+str(l+1)],grads[\"b\"+str(l+1)])\n",
        "        \n",
        "    return grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHzUwOKrmqG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''################ UPDATE PARAMETERS ###################'''\n",
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    \n",
        "    L= len(parameters)//2\n",
        "    for l in range(L):\n",
        "        parameters[\"W\"+str(l+1)] = parameters[\"W\"+str(l+1)] - learning_rate*grads[\"dW\"+str(l+1)]\n",
        "        parameters[\"b\"+str(l+1)] = parameters[\"b\"+str(l+1)] - learning_rate*grads[\"db\"+str(l+1)]\n",
        "        \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP91xstGmqHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''############# DEFINING DIMENSIONS FOR THE LAYERS ##############'''\n",
        "layers_dims = [X_train.shape[0], 800, 500, 128 , Y_train.shape[0]] #  4-layer model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PDv9OfxmqHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''################## L LAYER MODEL ###############'''\n",
        "def L_layer_model(X, Y, layer_dims,learning_rate=0.076, mini_batch_size= 128,  num_epochs=500, print_cost=False):\n",
        "    \n",
        "    costs=[] #to plot the graph\n",
        "    seed = 56\n",
        "    m = X.shape[1]\n",
        "\n",
        "\n",
        "    #Initialize Parameters\n",
        "    parameters = initialize_parameters_deep(layer_dims)\n",
        "    \n",
        "    for i in range(num_epochs):\n",
        "      seed = seed +1\n",
        "      minibatches = random_mini_batches(X, Y, mini_batch_size, seed)\n",
        "      cost_total = 0\n",
        "\n",
        "      for mini_batch in minibatches:\n",
        "        #Select a mini_batch\n",
        "        (minibatch_X, minibatch_Y) = mini_batch\n",
        "\n",
        "        #Forward Propagation on mini_batch\n",
        "        AL, caches = L_model_forward(minibatch_X, parameters)\n",
        "\n",
        "        #Compute Cost and add to the total cost\n",
        "        cost_total += compute_cost(AL, minibatch_Y)\n",
        "\n",
        "        #Backward Propagation on mini_batch\n",
        "        grads = L_model_backward(AL, minibatch_Y, caches)\n",
        "\n",
        "        #Update Parameters of W & b\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "        \n",
        "      cost_avg = cost_total/m\n",
        "\n",
        "      if print_cost and i%2 == 0:\n",
        "        print (\"Cost after epoch %i: %f\" %(i, cost_avg))\n",
        "        costs.append(cost_avg)\n",
        "\n",
        "    '''Plot the Cost'''\n",
        "    plt.plot(np.squeeze(costs))\n",
        "    plt.ylabel(\"cost\")\n",
        "    plt.xlabel(\"Epochs (per hundred)\")\n",
        "    plt.title(\"Learning rate: \"+str(learning_rate))\n",
        "    plt.show()\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scIldKacmqHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = L_layer_model(X_train, Y_train, layers_dims, mini_batch_size=2048, num_epochs= 10, print_cost = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7S10e5RmqHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################### PREDICTION ####################\n",
        "def predict(parameters, X):\n",
        "    '''Use Forward Propagation and parameters to compute A2'''\n",
        "    AL, cache = L_model_forward(X, parameters,print_AL=True)\n",
        "    \n",
        "    print(\"Shape of AL\",AL.shape)\n",
        "    print(AL[:,0:5])\n",
        "    predictions = np.where(AL == np.amax(AL, axis=0))\n",
        "    print(predictions)\n",
        "    #the predictions ia a two tuple \n",
        "    return predictions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpkbAu1oluN3",
        "colab_type": "code",
        "outputId": "2b08a15d-2130-4bb8-f255-db90eeb8de68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "######################## PREDICTION ON TEST SET #######################\n",
        "Y2 = predict(parameters, X_test)\n",
        "print(Y2.shape)\n",
        "\n",
        "result = [Y2 == Y_test]\n",
        "\n",
        "# result is a list, in which the first is an array of boolean values\n",
        "#so we separate it out using result[0]\n",
        "print(result[0])\n",
        "count = np.count_nonzero(result[0]) ##Number of true values in the list accuracy\n",
        "count\n",
        "\n",
        "#accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " ...\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]]\n",
            "Shape of AL (10, 10000)\n",
            "[[nan nan nan nan nan]\n",
            " [nan nan nan nan nan]\n",
            " [nan nan nan nan nan]\n",
            " [nan nan nan nan nan]\n",
            " [nan nan nan nan nan]\n",
            " [nan nan nan nan nan]\n",
            " [nan nan nan nan nan]\n",
            " [nan nan nan nan nan]\n",
            " [nan nan nan nan nan]\n",
            " [nan nan nan nan nan]]\n",
            "(array([], dtype=int64), array([], dtype=int64))\n",
            "(0,)\n",
            "False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}